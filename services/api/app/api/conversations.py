"""Conversation management API endpoints"""
import logging
from typing import Optional, List
from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel
from sqlalchemy.orm import Session
from openai import OpenAI

from ..db import get_db
from ..services.conversation_service import ConversationService
from ..services.retrieval import search
from ..services.intent_recognizer import recognize_intent, get_intent_recognizer, IntentType
from ..services.interaction_flow_trigger import detect_interaction_trigger
from ..models.user import User
from ..models.config import InteractionFlow
from ..config import settings
from .auth import get_current_user, get_current_user_optional

logger = logging.getLogger(__name__)

# Initialize OpenAI client
_llm_client = None

def get_llm_client():
    global _llm_client
    if _llm_client is None:
        _llm_client = OpenAI(
            api_key=settings.upstream_llm_key,
            base_url=settings.upstream_llm_url.replace("/chat/completions", ""),
        )
    return _llm_client

router = APIRouter(prefix="/api/conversations", tags=["conversations"])


# ==================== Request/Response Models ====================

class CreateConversationRequest(BaseModel):
    title: Optional[str] = None
    scenario_id: Optional[str] = None


class UpdateConversationRequest(BaseModel):
    title: Optional[str] = None
    tags: Optional[List[str]] = None
    scenario_id: Optional[str] = None


class SendMessageRequest(BaseModel):
    content: str


class FeedbackRequest(BaseModel):
    feedback: str  # positive/negative
    feedback_text: Optional[str] = None


class CreateShareRequest(BaseModel):
    allow_copy: bool = True
    expires_in_days: Optional[int] = None


class ConversationResponse(BaseModel):
    id: int
    conversation_id: str
    title: Optional[str]
    summary: Optional[str]
    status: str
    is_pinned: bool
    message_count: int
    last_message_at: Optional[str]
    tags: List
    scenario_id: Optional[str]
    created_at: Optional[str]
    updated_at: Optional[str]


class InteractionTriggerInfo(BaseModel):
    """äº¤äº’æµç¨‹è§¦å‘ä¿¡æ¯"""
    flow_id: str
    flow_name: str
    description: Optional[str] = None
    confidence: float
    reason: str


class MessageResponse(BaseModel):
    model_config = {"protected_namespaces": ()}
    
    id: int
    message_id: str
    role: str
    content: str
    sources: List
    feedback: Optional[str]
    tokens_used: Optional[int]
    model_used: Optional[str]
    latency_ms: Optional[int]
    created_at: Optional[str]
    # äº¤äº’æµç¨‹è§¦å‘ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    interaction_trigger: Optional[InteractionTriggerInfo] = None


class ConversationListResponse(BaseModel):
    pinned: List[ConversationResponse]
    today: List[ConversationResponse]
    yesterday: List[ConversationResponse]
    this_week: List[ConversationResponse]
    earlier: List[ConversationResponse]


# ==================== API Endpoints ====================

@router.get("", response_model=ConversationListResponse)
async def list_conversations(
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–ç”¨æˆ·çš„å¯¹è¯åˆ—è¡¨ï¼ˆåˆ†ç»„ï¼‰"""
    service = ConversationService(db)
    groups = service.list_conversations_grouped(str(user.id))
    
    return ConversationListResponse(
        pinned=[ConversationResponse(**c.to_dict()) for c in groups["pinned"]],
        today=[ConversationResponse(**c.to_dict()) for c in groups["today"]],
        yesterday=[ConversationResponse(**c.to_dict()) for c in groups["yesterday"]],
        this_week=[ConversationResponse(**c.to_dict()) for c in groups["this_week"]],
        earlier=[ConversationResponse(**c.to_dict()) for c in groups["earlier"]]
    )


@router.post("", response_model=ConversationResponse)
async def create_conversation(
    body: CreateConversationRequest,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ›å»ºæ–°å¯¹è¯"""
    service = ConversationService(db)
    conv = service.create_conversation(
        user_id=str(user.id),
        title=body.title,
        scenario_id=body.scenario_id
    )
    return ConversationResponse(**conv.to_dict())


@router.get("/search")
async def search_conversations(
    q: str,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æœç´¢å†å²å¯¹è¯"""
    service = ConversationService(db)
    results = service.search_conversations(str(user.id), q)
    return {"results": [c.to_dict() for c in results]}


@router.get("/{conversation_id}", response_model=ConversationResponse)
async def get_conversation(
    conversation_id: str,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–å¯¹è¯è¯¦æƒ…"""
    service = ConversationService(db)
    conv = service.get_conversation(conversation_id, str(user.id))
    
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    return ConversationResponse(**conv.to_dict())


@router.put("/{conversation_id}", response_model=ConversationResponse)
async def update_conversation(
    conversation_id: str,
    body: UpdateConversationRequest,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æ›´æ–°å¯¹è¯"""
    service = ConversationService(db)
    conv = service.update_conversation(
        conversation_id,
        str(user.id),
        title=body.title,
        tags=body.tags,
        scenario_id=body.scenario_id
    )
    
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    return ConversationResponse(**conv.to_dict())


@router.delete("/{conversation_id}")
async def delete_conversation(
    conversation_id: str,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ é™¤å¯¹è¯"""
    service = ConversationService(db)
    success = service.delete_conversation(conversation_id, str(user.id))
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    return {"message": "Conversation deleted"}


@router.post("/{conversation_id}/archive", response_model=ConversationResponse)
async def archive_conversation(
    conversation_id: str,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """å½’æ¡£å¯¹è¯"""
    service = ConversationService(db)
    conv = service.archive_conversation(conversation_id, str(user.id))
    
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    return ConversationResponse(**conv.to_dict())


@router.post("/{conversation_id}/pin", response_model=ConversationResponse)
async def pin_conversation(
    conversation_id: str,
    pinned: bool = True,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ç½®é¡¶/å–æ¶ˆç½®é¡¶"""
    service = ConversationService(db)
    conv = service.pin_conversation(conversation_id, str(user.id), pinned)
    
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    return ConversationResponse(**conv.to_dict())


# ==================== Message Endpoints ====================

@router.get("/{conversation_id}/messages")
async def get_messages(
    conversation_id: str,
    limit: int = 50,
    offset: int = 0,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–å¯¹è¯æ¶ˆæ¯åˆ—è¡¨"""
    service = ConversationService(db)
    
    # éªŒè¯ç”¨æˆ·æœ‰æƒé™è®¿é—®è¯¥å¯¹è¯
    conv = service.get_conversation(conversation_id, str(user.id))
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    messages = service.get_messages(conversation_id, limit, offset)
    return {"messages": [m.to_dict() for m in messages]}


@router.post("/{conversation_id}/messages", response_model=MessageResponse)
async def send_message(
    conversation_id: str,
    body: SendMessageRequest,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """å‘é€æ¶ˆæ¯ï¼ˆè§¦å‘ RAG å›ç­”ï¼Œæ”¯æŒäº¤äº’æµç¨‹æ™ºèƒ½è§¦å‘ï¼‰"""
    service = ConversationService(db)
    
    # éªŒè¯å¯¹è¯å­˜åœ¨
    conv = service.get_conversation(conversation_id, str(user.id))
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    user_message = service.add_message(
        conversation_id=conversation_id,
        role="user",
        content=body.content
    )
    
    # ==================== äº¤äº’æµç¨‹æ™ºèƒ½è§¦å‘æ£€æµ‹ ====================
    interaction_trigger_info = None
    optimized_query = body.content  # é»˜è®¤ä½¿ç”¨åŸå§‹æŸ¥è¯¢
    user_context = {}  # ç”¨æˆ·æ„å›¾ä¸Šä¸‹æ–‡
    
    try:
        client = get_llm_client()
        trigger_result = detect_interaction_trigger(
            db=db,
            query=body.content,
            llm_client=client,
            use_llm=True
        )
        
        # ä¿å­˜ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆæ— è®ºæ˜¯å¦è§¦å‘æµç¨‹ï¼‰
        user_context = trigger_result.user_context or {}
        
        if trigger_result.skip_flow and trigger_result.direct_query:
            # LLM åˆ¤æ–­ç”¨æˆ·å·²æä¾›è¶³å¤Ÿä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢æœç´¢
            logger.info(f"Skip flow, direct search with: {trigger_result.direct_query}")
            optimized_query = trigger_result.direct_query
            # ç»§ç»­æ‰§è¡Œ RAG æµç¨‹ï¼Œä½†ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢
            
        elif trigger_result.should_trigger and trigger_result.flow_id:
            # è·å–æµç¨‹è¯¦æƒ…
            flow = db.query(InteractionFlow).filter(
                InteractionFlow.flow_id == trigger_result.flow_id,
                InteractionFlow.is_active == True
            ).first()
            
            if flow:
                logger.info(f"Interaction flow triggered: {flow.flow_id} (conf={trigger_result.confidence:.2f})")
                interaction_trigger_info = InteractionTriggerInfo(
                    flow_id=flow.flow_id,
                    flow_name=flow.name,
                    description=flow.description,
                    confidence=trigger_result.confidence,
                    reason=trigger_result.reason
                )
                
                # ç”Ÿæˆå¼•å¯¼ç”¨æˆ·å¼€å§‹äº¤äº’æµç¨‹çš„å›å¤
                assistant_content = _generate_flow_intro_message(flow, trigger_result)
                sources = []
                model_used = "interaction_trigger"
                
                assistant_message = service.add_message(
                    conversation_id=conversation_id,
                    role="assistant",
                    content=assistant_content,
                    sources=sources,
                    model_used=model_used
                )
                
                response_dict = assistant_message.to_dict()
                response_dict["interaction_trigger"] = interaction_trigger_info.model_dump()
                return MessageResponse(**response_dict)
                
    except Exception as e:
        logger.warning(f"Interaction flow trigger detection failed: {e}")
        # ç»§ç»­æ­£å¸¸ RAG æµç¨‹
    
    # ==================== æ­£å¸¸ RAG å›ç­”æµç¨‹ ====================
    # ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢ï¼ˆå¯èƒ½æ˜¯ LLM æå–çš„æ›´ç²¾å‡†çš„æœç´¢è¯ï¼‰
    try:
        rag_result = await _generate_rag_response(
            query=optimized_query,
            conversation_id=conversation_id,
            scenario_id=conv.scenario_id,
            db=db,
            user_context=user_context  # ä¼ é€’ä¸Šä¸‹æ–‡
        )
        assistant_content = rag_result["answer"]
        sources = rag_result["sources"]
        model_used = rag_result.get("model", "qwen-max")
        interaction_trigger_info = rag_result.get("interaction_trigger")
    except Exception as e:
        logger.error(f"RAG generation error: {e}")
        assistant_content = f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚é”™è¯¯ä¿¡æ¯ï¼š{str(e)}"
        sources = []
        model_used = "qwen-max"
    
    assistant_message = service.add_message(
        conversation_id=conversation_id,
        role="assistant",
        content=assistant_content,
        sources=sources,
        model_used=model_used
    )
    
    response_dict = assistant_message.to_dict()
    if interaction_trigger_info:
        response_dict["interaction_trigger"] = interaction_trigger_info.model_dump() if hasattr(interaction_trigger_info, 'model_dump') else interaction_trigger_info
    return MessageResponse(**response_dict)


def _generate_flow_intro_message(flow: InteractionFlow, trigger_result) -> str:
    """ç”Ÿæˆäº¤äº’æµç¨‹å¼•å¯¼æ¶ˆæ¯"""
    intro_messages = {
        "quote_calc": "ä¸ºäº†ç»™æ‚¨å‡†ç¡®çš„æŠ¥ä»·ä¿¡æ¯ï¼Œæˆ‘éœ€è¦äº†è§£ä¸€äº›ç»†èŠ‚ã€‚è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æŠ¥ä»·æµ‹ç®—æµç¨‹ã€‚",
        "case_search": "ä¸ºäº†æ‰¾åˆ°æœ€åŒ¹é…æ‚¨éœ€æ±‚çš„æ¡ˆä¾‹ï¼Œæˆ‘éœ€è¦äº†è§£ä¸€äº›ä¿¡æ¯ã€‚è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æ¡ˆä¾‹æ£€ç´¢ã€‚",
        "contribution_info": "æ„Ÿè°¢æ‚¨æ„¿æ„è¡¥å……ææ–™ï¼è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¡«å†™ææ–™ä¿¡æ¯ã€‚",
    }
    
    default_intro = f"ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œæˆ‘éœ€è¦æ”¶é›†ä¸€äº›ä¿¡æ¯ã€‚è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹ã€Œ{flow.name}ã€æµç¨‹ã€‚"
    
    return intro_messages.get(flow.flow_id, default_intro)


async def _generate_rag_response(
    query: str,
    conversation_id: str,
    scenario_id: Optional[str] = None,
    db: Session = None,
    user_context: dict = None
) -> dict:
    """
    Generate RAG response using retrieval and LLM
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆå¯èƒ½æ˜¯ LLM ä¼˜åŒ–åçš„ï¼‰
        conversation_id: å¯¹è¯ ID
        scenario_id: åœºæ™¯ ID
        db: æ•°æ®åº“ä¼šè¯
        user_context: ç”¨æˆ·æ„å›¾ä¸Šä¸‹æ–‡ï¼ˆLLM æå–çš„ä¸»é¢˜ã€å…³é”®è¯ç­‰ï¼‰
    
    Returns:
        dict with keys: answer, sources, model, interaction_trigger (optional)
    """
    user_context = user_context or {}
    
    # 1. æ„å›¾è¯†åˆ«
    client = get_llm_client()
    intent_recognizer = get_intent_recognizer(client)
    
    try:
        intent_result = intent_recognizer.recognize(query)
        logger.info(f"Intent recognized: {intent_result.intent_type}")
    except Exception as e:
        logger.warning(f"Intent recognition failed: {e}")
        intent_result = None
    
    # 2. å¢å¼ºæ£€ç´¢æŸ¥è¯¢ - ç»“åˆç”¨æˆ·ä¸Šä¸‹æ–‡
    enhanced_query = query
    if user_context:
        topic = user_context.get("topic", "")
        keywords = user_context.get("keywords", [])
        product = user_context.get("product", "")
        
        # å¦‚æœæœ‰æå–çš„ä¸»é¢˜/å…³é”®è¯ï¼Œæ·»åŠ åˆ°æŸ¥è¯¢ä¸­ä»¥æé«˜æ£€ç´¢ç²¾åº¦
        context_terms = [topic] if topic else []
        context_terms.extend(keywords)
        if product:
            context_terms.append(product)
        
        if context_terms:
            # å°†ä¸Šä¸‹æ–‡å…³é”®è¯åŠ å…¥æŸ¥è¯¢ï¼Œé¿å…é‡å¤
            unique_terms = [t for t in context_terms if t and t.lower() not in query.lower()]
            if unique_terms:
                enhanced_query = f"{query} {' '.join(unique_terms)}"
                logger.info(f"Enhanced query with context: {enhanced_query}")
    
    # 3. æ£€ç´¢çŸ¥è¯†
    try:
        hits = search(enhanced_query, top_k=5, intent_result=intent_result)
        logger.info(f"Retrieved {len(hits)} hits")
    except Exception as e:
        logger.error(f"Retrieval error: {e}")
        hits = []
    
    # 3. æ„å»ºä¸Šä¸‹æ–‡
    sources = []
    context_parts = []
    
    for hit in hits[:5]:
        title = hit.get("title", "æœªçŸ¥æ ‡é¢˜")
        summary = hit.get("summary", "")
        body = hit.get("body", "")[:1500]
        source_file = hit.get("source_file", "")
        
        context_parts.append(f"ã€æ¥æº: {source_file}ã€‘\næ ‡é¢˜: {title}\næ‘˜è¦: {summary}\nè¯¦æƒ…: {body}")
        
        sources.append({
            "id": hit.get("id"),
            "title": title,
            "type": hit.get("ku_type", "core"),
            "source_file": source_file,
            "score": hit.get("score", 0)
        })
    
    # 4. æ„å»º Prompt
    if context_parts:
        context = "\n\n---\n\n".join(context_parts)
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„çŸ¥è¯†å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

{context}

å›ç­”è¦æ±‚ï¼š
1. åŸºäºä¸Šè¿°å†…å®¹å‡†ç¡®å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. åœ¨é€‚å½“ä½ç½®å¼•ç”¨æ¥æºï¼Œæ ¼å¼å¦‚ã€æ¥æº: xxxã€‘
3. å¦‚æœæ£€ç´¢å†…å®¹ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·å¦‚å®è¯´æ˜
4. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€

æ ¼å¼åŒ–è¾“å‡ºè¦æ±‚ï¼ˆä½¿ç”¨ Markdownï¼‰ï¼š
- **å¯¹æ¯”ç±»é—®é¢˜**ï¼šä½¿ç”¨ Markdown è¡¨æ ¼å±•ç¤ºï¼Œå¦‚ | å‚æ•° | Aäº§å“ | Bäº§å“ |
- **å¤šæ­¥éª¤/æµç¨‹**ï¼šä½¿ç”¨æœ‰åºåˆ—è¡¨ 1. 2. 3.
- **å¤šè¦ç‚¹**ï¼šä½¿ç”¨æ— åºåˆ—è¡¨ - æˆ– *
- **ä»£ç /é…ç½®**ï¼šä½¿ç”¨ä»£ç å— ```è¯­è¨€å
- **é‡ç‚¹å†…å®¹**ï¼šä½¿ç”¨ **åŠ ç²—** æˆ– `è¡Œå†…ä»£ç `
- **æµç¨‹å›¾**ï¼šå¯ä½¿ç”¨ Mermaid è¯­æ³• ```mermaid

è¡¨æ ¼ç¤ºä¾‹ï¼š
| å¯¹æ¯”é¡¹ | äº§å“A | äº§å“B |
|--------|-------|-------|
| ç²¾åº¦   | 0.01mm | 0.02mm |
| äº§èƒ½   | 5000ç‰‡/h | 3500ç‰‡/h |"""
    else:
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åŠ©æ‰‹ã€‚å½“å‰çŸ¥è¯†åº“æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚
è¯·å‘ŠçŸ¥ç”¨æˆ·æš‚æ— ç›¸å…³èµ„æ–™ï¼Œå¹¶è¯¢é—®æ˜¯å¦å¯ä»¥æä¾›æ›´å¤šä¿¡æ¯å¸®åŠ©å®Œå–„çŸ¥è¯†åº“ã€‚"""
    
    # 5. è°ƒç”¨ LLM ç”Ÿæˆå›ç­”
    try:
        response = client.chat.completions.create(
            model="qwen-max",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            temperature=0.7,
            max_tokens=2048
        )
        answer = response.choices[0].message.content
        model = response.model if hasattr(response, 'model') else "qwen-max"
    except Exception as e:
        logger.error(f"LLM call failed: {e}")
        if hits:
            # å›é€€ï¼šç›´æ¥è¿”å›æ£€ç´¢ç»“æœæ‘˜è¦
            summaries = [f"â€¢ {h.get('title', '')}: {h.get('summary', '')[:100]}" for h in hits[:3]]
            answer = f"æŠ±æ­‰ï¼ŒAI å›ç­”ç”Ÿæˆé‡åˆ°é—®é¢˜ï¼Œä»¥ä¸‹æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ï¼š\n\n" + "\n\n".join(summaries)
        else:
            answer = "æŠ±æ­‰ï¼Œå½“å‰æ— æ³•ç”Ÿæˆå›ç­”ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        model = "fallback"
    
    return {
        "answer": answer,
        "sources": sources,
        "model": model
    }


@router.put("/{conversation_id}/messages/{message_id}/feedback")
async def update_feedback(
    conversation_id: str,
    message_id: str,
    body: FeedbackRequest,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æ›´æ–°æ¶ˆæ¯åé¦ˆ"""
    service = ConversationService(db)
    
    # éªŒè¯å¯¹è¯å±äºç”¨æˆ·
    conv = service.get_conversation(conversation_id, str(user.id))
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    message = service.update_message_feedback(message_id, body.feedback, body.feedback_text)
    
    if not message:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Message not found"
        )
    
    return {"message": "Feedback updated"}


# ==================== Share Endpoints ====================

# ==================== Export Endpoint ====================

class ExportResponse(BaseModel):
    content: str
    filename: str


@router.get("/{conversation_id}/export", response_model=ExportResponse)
async def export_conversation(
    conversation_id: str,
    format: str = "markdown",  # markdown or json
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """å¯¼å‡ºå¯¹è¯"""
    service = ConversationService(db)
    
    # éªŒè¯å¯¹è¯å±äºç”¨æˆ·
    conv = service.get_conversation(conversation_id, str(user.id))
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    messages = service.get_messages(conversation_id, limit=1000)
    
    if format == "json":
        import json
        content = json.dumps({
            "conversation": conv.to_dict(),
            "messages": [m.to_dict() for m in messages]
        }, ensure_ascii=False, indent=2)
        filename = f"conversation-{conversation_id}.json"
    else:
        # Markdown format
        lines = [
            f"# {conv.title or 'å¯¹è¯å¯¼å‡º'}",
            "",
            f"å¯¼å‡ºæ—¶é—´: {conv.created_at}",
            "",
            "---",
            ""
        ]
        
        for msg in messages:
            role = "**ç”¨æˆ·**" if msg.role == "user" else "**åŠ©æ‰‹**"
            lines.append(role)
            lines.append("")
            lines.append(msg.content)
            lines.append("")
            
            # Add sources if available
            if msg.sources:
                lines.append("ğŸ“ æ¥æºï¼š")
                for src in msg.sources:
                    title = src.get("title", "æœªçŸ¥") if isinstance(src, dict) else str(src)
                    lines.append(f"- {title}")
                lines.append("")
            
            lines.append("---")
            lines.append("")
        
        content = "\n".join(lines)
        filename = f"conversation-{conversation_id}.md"
    
    return ExportResponse(content=content, filename=filename)


# ==================== Share Endpoints ====================

@router.post("/{conversation_id}/share")
async def create_share(
    conversation_id: str,
    body: CreateShareRequest,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ›å»ºåˆ†äº«é“¾æ¥"""
    service = ConversationService(db)
    
    # éªŒè¯å¯¹è¯å±äºç”¨æˆ·
    conv = service.get_conversation(conversation_id, str(user.id))
    if not conv:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    share = service.create_share(
        conversation_id=conversation_id,
        user_id=user.id,
        allow_copy=body.allow_copy,
        expires_in_days=body.expires_in_days
    )
    
    return {
        "share_token": share.share_token,
        "share_url": f"/share/{share.share_token}",
        "expires_at": share.expires_at.isoformat() if share.expires_at else None
    }


@router.delete("/{conversation_id}/share")
async def delete_share(
    conversation_id: str,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """å–æ¶ˆåˆ†äº«"""
    service = ConversationService(db)
    success = service.delete_share(conversation_id, user.id)
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Share not found"
        )
    
    return {"message": "Share deleted"}


# ==================== Public Share Access ====================

@router.get("/share/{token}")
async def get_shared_conversation(
    token: str,
    db: Session = Depends(get_db)
):
    """è·å–åˆ†äº«çš„å¯¹è¯ï¼ˆå…¬å¼€è®¿é—®ï¼‰"""
    service = ConversationService(db)
    result = service.get_shared_conversation(token)
    
    if not result:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Share not found or expired"
        )
    
    return result

