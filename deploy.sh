#!/bin/bash
#===============================================================================
# AI Data Factory - ä¸€é”®éƒ¨ç½²è„šæœ¬
# é€‚ç”¨äºé˜¿é‡Œäº‘ ECS (Ubuntu/Debian)
#===============================================================================

set -e

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

# é…ç½®å˜é‡
INSTALL_DIR="${INSTALL_DIR:-/opt/datafactory}"
PUBLIC_IP="${PUBLIC_IP:-$(curl -s ifconfig.me 2>/dev/null || hostname -I | awk '{print $1}')}"

echo ""
echo "========================================"
echo "   AI Data Factory ä¸€é”®éƒ¨ç½²"
echo "   ç›®æ ‡ç›®å½•: $INSTALL_DIR"
echo "   å…¬ç½‘ IP: $PUBLIC_IP"
echo "========================================"
echo ""

#===============================================================================
# 1. æ£€æŸ¥ Docker
#===============================================================================
check_docker() {
    log_info "æ£€æŸ¥ Docker ç¯å¢ƒ..."
    
    if ! command -v docker &> /dev/null; then
        log_warn "Docker æœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…..."
        curl -fsSL https://get.docker.com | sh
        systemctl enable docker
        systemctl start docker
        log_success "Docker å®‰è£…å®Œæˆ"
    else
        log_success "Docker å·²å®‰è£…: $(docker --version)"
    fi
    
    # æ£€æŸ¥ docker compose
    if ! docker compose version &> /dev/null; then
        log_warn "Docker Compose æ’ä»¶æœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…..."
        apt-get update && apt-get install -y docker-compose-plugin
    fi
    log_success "Docker Compose å·²å°±ç»ª"
}

#===============================================================================
# 2. åˆ›å»ºç›®å½•å’Œé…ç½®
#===============================================================================
setup_project() {
    log_info "è®¾ç½®é¡¹ç›®ç›®å½•..."
    
    mkdir -p "$INSTALL_DIR"
    cd "$INSTALL_DIR"
    
    # å¦‚æœæ˜¯ä» git å…‹éš†
    if [ -d ".git" ]; then
        log_info "æ›´æ–°ä»£ç ..."
        git pull
    fi
    
    log_success "é¡¹ç›®ç›®å½•å·²å°±ç»ª: $INSTALL_DIR"
}

#===============================================================================
# 3. ç”Ÿæˆç¯å¢ƒé…ç½®
#===============================================================================
create_env() {
    log_info "ç”Ÿæˆç¯å¢ƒé…ç½®æ–‡ä»¶..."
    
    if [ ! -f ".env" ]; then
        cat > .env << EOF
# ========================================
# AI Data Factory ç¯å¢ƒé…ç½®
# ç”Ÿæˆæ—¶é—´: $(date)
# ========================================

# PostgreSQL
POSTGRES_USER=adf
POSTGRES_PASSWORD=adfpass$(openssl rand -hex 4)
POSTGRES_DB=adf
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# MinIO
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio$(openssl rand -hex 4)
MINIO_URL=http://minio:9000

# OpenSearch
OPENSEARCH_HOST=opensearch
OPENSEARCH_PORT=9200
OPENSEARCH_INDEX=knowledge_units
OPENSEARCH_INITIAL_ADMIN_PASSWORD=admin123

# JWT
JWT_SECRET=$(openssl rand -hex 32)
JWT_ALGO=HS256

# LLM (é˜¿é‡Œäº‘ç™¾ç‚¼ Qwen)
UPSTREAM_LLM_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
DASHSCOPE_API_KEY=
UPSTREAM_LLM_API_KEY=\${DASHSCOPE_API_KEY}
DEFAULT_MODEL=qwen-plus

# Langfuse (å¯é€‰ï¼Œéƒ¨ç½²ååœ¨ Web UI è·å–)
LANGFUSE_HOST=http://langfuse:3000
LANGFUSE_PUBLIC_KEY=
LANGFUSE_API_KEY=

# n8n
N8N_WEBHOOK_URL=http://${PUBLIC_IP}:5678/

# Nginx Basic Auth (ç”¨äºä¿æŠ¤ Chat å…¥å£)
BASIC_AUTH_USER=admin
BASIC_AUTH_PASS=admin$(openssl rand -hex 4)

# Gateway
GATEWAY_SCENARIO_DEFAULT=sales_qa
EOF
        log_success "å·²ç”Ÿæˆ .env æ–‡ä»¶"
        log_warn "è¯·ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ DASHSCOPE_API_KEY"
    else
        log_info ".env æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ"
    fi
}

#===============================================================================
# 4. åˆ›å»ºå¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶
#===============================================================================
create_dirs() {
    log_info "åˆ›å»ºå¿…è¦çš„ç›®å½•..."
    
    mkdir -p infra/nginx/certs
    mkdir -p services/dq/uncommitted/data_docs
    mkdir -p services/api/static
    mkdir -p workflows
    
    # åˆ›å»º .htpasswd æ–‡ä»¶
    if [ ! -f "infra/nginx/.htpasswd" ]; then
        source .env 2>/dev/null || true
        BASIC_AUTH_USER="${BASIC_AUTH_USER:-admin}"
        BASIC_AUTH_PASS="${BASIC_AUTH_PASS:-admin123}"
        
        docker run --rm --entrypoint htpasswd httpd:2 -Bbn "$BASIC_AUTH_USER" "$BASIC_AUTH_PASS" > infra/nginx/.htpasswd
        log_success "å·²ç”Ÿæˆ .htpasswd æ–‡ä»¶"
    fi
    
    log_success "ç›®å½•åˆ›å»ºå®Œæˆ"
}

#===============================================================================
# 5. å¯åŠ¨åŸºç¡€æœåŠ¡
#===============================================================================
start_base_services() {
    log_info "å¯åŠ¨åŸºç¡€æœåŠ¡ (postgres, minio, opensearch)..."
    
    docker compose up -d postgres minio opensearch redis
    
    log_info "ç­‰å¾…æœåŠ¡å°±ç»ª..."
    sleep 15
    
    # ç­‰å¾… PostgreSQL
    for i in {1..30}; do
        if docker compose exec -T postgres pg_isready -U adf &>/dev/null; then
            log_success "PostgreSQL å·²å°±ç»ª"
            break
        fi
        echo -n "."
        sleep 2
    done
    
    # ç­‰å¾… OpenSearch
    for i in {1..30}; do
        if curl -s http://localhost:9200 &>/dev/null; then
            log_success "OpenSearch å·²å°±ç»ª"
            break
        fi
        echo -n "."
        sleep 2
    done
    
    # ç­‰å¾… MinIO
    for i in {1..30}; do
        if curl -s http://localhost:9000/minio/health/live &>/dev/null; then
            log_success "MinIO å·²å°±ç»ª"
            break
        fi
        echo -n "."
        sleep 2
    done
}

#===============================================================================
# 6. åˆå§‹åŒ–æ•°æ®åº“
#===============================================================================
init_databases() {
    log_info "åˆå§‹åŒ–æ•°æ®åº“..."
    
    source .env
    
    # é‡è¦ï¼šè®¾ç½® PostgreSQL ç”¨æˆ·å¯†ç ï¼ˆå› ä¸º PostgreSQL åªåœ¨é¦–æ¬¡å¯åŠ¨æ—¶è¯»å– POSTGRES_PASSWORDï¼‰
    # è¿™ç¡®ä¿å¯†ç ä¸ .env ä¸­çš„é…ç½®ä¸€è‡´
    log_info "åŒæ­¥ PostgreSQL ç”¨æˆ·å¯†ç ..."
    docker compose exec -T postgres psql -U "$POSTGRES_USER" -c \
        "ALTER USER $POSTGRES_USER WITH PASSWORD '$POSTGRES_PASSWORD';" || true
    
    # åˆ›å»º Airflow æ•°æ®åº“
    docker compose exec -T postgres psql -U "$POSTGRES_USER" -tc \
        "SELECT 1 FROM pg_database WHERE datname='airflow';" | grep -q 1 || \
        docker compose exec -T postgres psql -U "$POSTGRES_USER" -c "CREATE DATABASE airflow;"
    
    # åˆ›å»º Langfuse æ•°æ®åº“
    docker compose exec -T postgres psql -U "$POSTGRES_USER" -tc \
        "SELECT 1 FROM pg_database WHERE datname='langfuse';" | grep -q 1 || \
        docker compose exec -T postgres psql -U "$POSTGRES_USER" -c "CREATE DATABASE langfuse;"
    
    # åˆ›å»º OpenMetadata æ•°æ®åº“
    docker compose exec -T postgres psql -U "$POSTGRES_USER" -tc \
        "SELECT 1 FROM pg_database WHERE datname='openmetadata';" | grep -q 1 || \
        docker compose exec -T postgres psql -U "$POSTGRES_USER" -c "CREATE DATABASE openmetadata;"
    
    log_success "æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ"
}

#===============================================================================
# 6.5 ä¿®å¤è„šæœ¬æ–‡ä»¶
#===============================================================================
fix_scripts() {
    log_info "ä¿®å¤è„šæœ¬æ–‡ä»¶ï¼ˆç§»é™¤ Windows æ¢è¡Œç¬¦å’Œ BOMï¼‰..."
    
    # ä¿®å¤æ‰€æœ‰ shell è„šæœ¬
    for script in scripts/*.sh; do
        if [ -f "$script" ]; then
            # ç§»é™¤ BOM
            sed -i '1s/^\xef\xbb\xbf//' "$script" 2>/dev/null || true
            # ç§»é™¤ Windows æ¢è¡Œç¬¦
            sed -i 's/\r$//' "$script" 2>/dev/null || true
            chmod +x "$script"
        fi
    done
    
    log_success "è„šæœ¬æ–‡ä»¶ä¿®å¤å®Œæˆ"
}

#===============================================================================
# 7. æ„å»ºå’Œå¯åŠ¨æ‰€æœ‰æœåŠ¡
#===============================================================================
start_all_services() {
    log_info "æ„å»ºè‡ªå®šä¹‰é•œåƒ..."
    docker compose build --parallel
    
    log_info "å¯åŠ¨æ‰€æœ‰æœåŠ¡..."
    docker compose up -d
    
    log_info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    sleep 30
    
    # ç­‰å¾… API æœåŠ¡å°±ç»ª
    log_info "ç­‰å¾… API æœåŠ¡å°±ç»ª..."
    for i in {1..30}; do
        if curl -s http://localhost:8000/health &>/dev/null; then
            log_success "API æœåŠ¡å·²å°±ç»ª"
            break
        fi
        echo -n "."
        sleep 2
    done
    echo ""
}

#===============================================================================
# 7.5 è¿è¡Œæ•°æ®åº“è¿ç§»
#===============================================================================
run_migrations() {
    log_info "è¿è¡Œ API æ•°æ®åº“è¿ç§» (Alembic)..."
    
    # ç­‰å¾… API å®¹å™¨å®Œå…¨å¯åŠ¨
    sleep 5
    
    # è¿è¡Œ Alembic è¿ç§»
    docker compose exec -T api alembic upgrade head || {
        log_warn "Alembic è¿ç§»å¤±è´¥ï¼Œå°è¯•åˆå§‹åŒ–..."
        docker compose exec -T api alembic stamp head || true
    }
    
    log_success "æ•°æ®åº“è¿ç§»å®Œæˆ"
}

#===============================================================================
# 8. åˆå§‹åŒ– MinIO å’Œ OpenSearch
#===============================================================================
init_storage() {
    log_info "åˆå§‹åŒ– MinIO buckets..."
    
    source .env
    
    docker compose run --rm -v "$(pwd)":/work -w /work \
        -e MINIO_URL=http://minio:9000 \
        -e MINIO_ROOT_USER="$MINIO_ROOT_USER" \
        -e MINIO_ROOT_PASSWORD="$MINIO_ROOT_PASSWORD" \
        api python scripts/create_buckets.py || log_warn "Buckets å¯èƒ½å·²å­˜åœ¨"
    
    log_info "åˆå§‹åŒ– OpenSearch ç´¢å¼•..."
    
    docker compose run --rm -v "$(pwd)":/work -w /work \
        -e OPENSEARCH_URL=http://opensearch:9200 \
        -e OPENSEARCH_INDEX=knowledge_units \
        api python scripts/create_opensearch_index.py || log_warn "ç´¢å¼•å¯èƒ½å·²å­˜åœ¨"
    
    log_info "æ·»åŠ ç§å­æ•°æ®..."
    
    docker compose run --rm -v "$(pwd)":/work -w /work \
        -e MINIO_URL=http://minio:9000 \
        -e MINIO_ROOT_USER="$MINIO_ROOT_USER" \
        -e MINIO_ROOT_PASSWORD="$MINIO_ROOT_PASSWORD" \
        api python scripts/seed_data.py || log_warn "ç§å­æ•°æ®å¯èƒ½å·²å­˜åœ¨"
    
    log_success "å­˜å‚¨åˆå§‹åŒ–å®Œæˆ"
}

#===============================================================================
# 9. è¿è¡Œåˆå§‹ Pipeline
#===============================================================================
run_initial_pipeline() {
    log_info "è¿è¡Œåˆå§‹ Pipeline..."
    
    # ç­‰å¾… Airflow å°±ç»ª
    for i in {1..30}; do
        if curl -s http://localhost:8080/health &>/dev/null; then
            log_success "Airflow å·²å°±ç»ª"
            break
        fi
        echo -n "."
        sleep 3
    done
    
    # è¿è¡Œ Pipeline
    TODAY=$(date +%Y-%m-%d)
    
    log_info "è¿è¡Œ ingest_to_bronze..."
    docker compose exec -T airflow airflow tasks test ingest_to_bronze ingest_files "$TODAY" 2>&1 | tail -5 || true
    
    log_info "è¿è¡Œ extract_to_silver..."
    docker compose exec -T airflow airflow tasks test extract_to_silver extract_text "$TODAY" 2>&1 | tail -5 || true
    
    log_info "è¿è¡Œ expand_and_rewrite_to_gold..."
    docker compose exec -T airflow airflow tasks test expand_and_rewrite_to_gold expand_and_rewrite "$TODAY" 2>&1 | tail -5 || true
    
    log_info "è¿è¡Œ index_to_opensearch..."
    docker compose exec -T airflow airflow tasks test index_to_opensearch index_knowledge_units "$TODAY" 2>&1 | tail -5 || true
    
    log_success "Pipeline è¿è¡Œå®Œæˆ"
}

#===============================================================================
# 10. éªŒè¯éƒ¨ç½²
#===============================================================================
verify_deployment() {
    log_info "éªŒè¯éƒ¨ç½²..."
    
    echo ""
    echo "========================================"
    echo "   æœåŠ¡çŠ¶æ€"
    echo "========================================"
    docker compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}" | head -20
    
    echo ""
    echo "========================================"
    echo "   å¥åº·æ£€æŸ¥"
    echo "========================================"
    
    # æ£€æŸ¥å„æœåŠ¡
    services=(
        "API:http://localhost:8000/health"
        "OpenSearch:http://localhost:9200"
        "MinIO:http://localhost:9001"
        "Airflow:http://localhost:8080"
        "Langfuse:http://localhost:3000"
        "Open-WebUI:http://localhost:3001"
        "n8n:http://localhost:5678"
        "Budibase:http://localhost:10000"
    )
    
    for svc in "${services[@]}"; do
        name="${svc%%:*}"
        url="${svc#*:}"
        status=$(curl -s -o /dev/null -w "%{http_code}" "$url" 2>/dev/null || echo "000")
        if [[ "$status" =~ ^(200|301|302|401|403)$ ]]; then
            echo -e "  ${GREEN}âœ“${NC} $name ($status)"
        else
            echo -e "  ${RED}âœ—${NC} $name ($status)"
        fi
    done
    
    # æ£€æŸ¥ç´¢å¼•
    echo ""
    DOC_COUNT=$(curl -s "http://localhost:9200/knowledge_units/_count" 2>/dev/null | python3 -c "import sys,json; print(json.load(sys.stdin).get('count', 0))" 2>/dev/null || echo "0")
    echo "  OpenSearch ç´¢å¼•æ–‡æ¡£æ•°: $DOC_COUNT"
}

#===============================================================================
# 11. æ‰“å°è®¿é—®ä¿¡æ¯
#===============================================================================
print_access_info() {
    source .env 2>/dev/null || true
    
    echo ""
    echo "========================================"
    echo "   ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
    echo "========================================"
    echo ""
    echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    echo "â”‚ æœåŠ¡             â”‚ åœ°å€                                   â”‚"
    echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
    echo "â”‚ ğŸ’¬ Chat (WebUI)  â”‚ http://${PUBLIC_IP}:3001               â”‚"
    echo "â”‚ ğŸ”§ API Docs      â”‚ http://${PUBLIC_IP}:8000/docs          â”‚"
    echo "â”‚ ğŸ“Š Langfuse      â”‚ http://${PUBLIC_IP}:3000               â”‚"
    echo "â”‚ ğŸ”„ n8n           â”‚ http://${PUBLIC_IP}:5678               â”‚"
    echo "â”‚ ğŸ“ Budibase      â”‚ http://${PUBLIC_IP}:10000              â”‚"
    echo "â”‚ ğŸŒ¬ï¸ Airflow       â”‚ http://${PUBLIC_IP}:8080               â”‚"
    echo "â”‚ ğŸ’¾ MinIO         â”‚ http://${PUBLIC_IP}:9001               â”‚"
    echo "â”‚ ğŸ” OpenSearch    â”‚ http://${PUBLIC_IP}:9200               â”‚"
    echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
    echo ""
    echo "é»˜è®¤è´¦æˆ·:"
    echo "  Airflow:  admin / admin123"
    echo "  MinIO:    ${MINIO_ROOT_USER:-minio} / ${MINIO_ROOT_PASSWORD:-æŸ¥çœ‹.env}"
    echo "  Budibase: admin@example.com / admin"
    echo ""
    echo "âš ï¸  é‡è¦æé†’:"
    echo "  1. è¯·ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ DASHSCOPE_API_KEY (é˜¿é‡Œäº‘ç™¾ç‚¼ API Key)"
    echo "  2. å¡«å…¥åé‡å¯ API: docker compose restart api airflow"
    echo "  3. åœ¨ Langfuse æ³¨å†Œåï¼Œè·å– API Keys å¡«å…¥ .env"
    echo ""
    echo "å¿«é€Ÿå‘½ä»¤:"
    echo "  make status   - æŸ¥çœ‹çŠ¶æ€"
    echo "  make verify   - éªŒè¯ RAG"
    echo "  make help     - æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤"
    echo ""
}

#===============================================================================
# ä¸»æµç¨‹
#===============================================================================
main() {
    log_info "å¼€å§‹éƒ¨ç½²..."
    
    check_docker
    setup_project
    create_env
    create_dirs
    fix_scripts
    start_base_services
    init_databases
    start_all_services
    run_migrations
    init_storage
    
    # æ£€æŸ¥æ˜¯å¦é…ç½®äº† API Key
    source .env 2>/dev/null || true
    if [ -n "$DASHSCOPE_API_KEY" ]; then
        run_initial_pipeline
    else
        log_warn "DASHSCOPE_API_KEY æœªé…ç½®ï¼Œè·³è¿‡ Pipeline è¿è¡Œ"
    fi
    
    verify_deployment
    print_access_info
    
    log_success "éƒ¨ç½²å®Œæˆï¼"
}

# æ”¯æŒå•ç‹¬è¿è¡ŒæŸä¸ªæ­¥éª¤
case "${1:-}" in
    docker)     check_docker ;;
    env)        create_env ;;
    dirs)       create_dirs ;;
    fix)        fix_scripts ;;
    base)       start_base_services ;;
    db)         init_databases ;;
    start)      start_all_services ;;
    migrate)    run_migrations ;;
    init)       init_storage ;;
    pipeline)   run_initial_pipeline ;;
    verify)     verify_deployment ;;
    info)       print_access_info ;;
    help)
        echo "ç”¨æ³•: $0 [æ­¥éª¤]"
        echo ""
        echo "æ­¥éª¤:"
        echo "  docker    - æ£€æŸ¥/å®‰è£… Docker"
        echo "  env       - ç”Ÿæˆ .env é…ç½®æ–‡ä»¶"
        echo "  dirs      - åˆ›å»ºå¿…è¦ç›®å½•"
        echo "  fix       - ä¿®å¤è„šæœ¬æ–‡ä»¶ï¼ˆBOM/æ¢è¡Œç¬¦ï¼‰"
        echo "  base      - å¯åŠ¨åŸºç¡€æœåŠ¡"
        echo "  db        - åˆå§‹åŒ–æ•°æ®åº“"
        echo "  start     - å¯åŠ¨æ‰€æœ‰æœåŠ¡"
        echo "  migrate   - è¿è¡Œæ•°æ®åº“è¿ç§»"
        echo "  init      - åˆå§‹åŒ–å­˜å‚¨ï¼ˆMinIO/OpenSearchï¼‰"
        echo "  pipeline  - è¿è¡Œåˆå§‹ Pipeline"
        echo "  verify    - éªŒè¯éƒ¨ç½²"
        echo "  info      - æ˜¾ç¤ºè®¿é—®ä¿¡æ¯"
        echo ""
        echo "ä¸å¸¦å‚æ•°è¿è¡Œå®Œæ•´éƒ¨ç½²æµç¨‹"
        ;;
    *)          main ;;
esac

